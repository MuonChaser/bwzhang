[{"content":"共轭先验（conjugate prior）是贝叶斯统计中的一个重要概念，使得后验分布与先验分布具有相同的函数形式，大大简化了贝叶斯推断的计算。\n1. 共轭先验的定义 1.1 基本定义 设似然函数为 $L(\\theta | x) = p(x | \\theta)$，先验分布为 $\\pi(\\theta)$。\n定义：如果先验分布 $\\pi(\\theta)$ 与后验分布 $\\pi(\\theta | x)$ 属于同一分布族，则称 $\\pi(\\theta)$ 是似然函数的共轭先验。\n1.2 数学表述 根据贝叶斯定理，后验分布为：\n$$\\pi(\\theta | x) = \\frac{p(x|\\theta) \\pi(\\theta)}{\\int p(x|\\theta) \\pi(\\theta) d\\theta} \\propto p(x|\\theta) \\pi(\\theta)$$\n若 $\\pi(\\theta) \\in \\mathcal{F}$（某个分布族），且 $\\pi(\\theta|x) \\in \\mathcal{F}$，则 $\\mathcal{F}$ 对应的分布是似然函数 $p(x|\\theta)$ 的共轭先验族。\n1.3 共轭先验的优点 计算便利：避免复杂的数值积分，有闭形式解 参数更新：先验参数和观测数据可通过简单规则组合更新 直观理解：超参数具有明确的概率解释 递推贝叶斯：新的后验可作为下一次观测的先验 2. 常见共轭分布对 2.1 正态-正态共轭（Gaussian-Gaussian Conjugacy） 似然：$X | \\mu \\sim N(\\mu, \\sigma_0^2)$，$\\sigma_0^2$ 已知\n先验：$\\mu \\sim N(\\mu_0, \\tau_0^2)$\n后验：$\\mu | X \\sim N(\\mu_n, \\tau_n^2)$\n参数更新规则：\n对单个观测 $x$： $$\\mu_n = \\frac{\\tau_0^{-2} \\mu_0 + \\sigma_0^{-2} x}{\\tau_0^{-2} + \\sigma_0^{-2}}$$\n$$\\tau_n^{-2} = \\tau_0^{-2} + \\sigma_0^{-2}$$\n对 $n$ 个独立观测 $x_1, \\ldots, x_n$，$\\bar{x} = \\frac{1}{n}\\sum_{i=1}^n x_i$： $$\\mu_n = \\frac{\\tau_0^{-2} \\mu_0 + n\\sigma_0^{-2} \\bar{x}}{\\tau_0^{-2} + n\\sigma_0^{-2}}$$\n$$\\tau_n^{-2} = \\tau_0^{-2} + n\\sigma_0^{-2}$$\n直观解释：后验均值是先验和数据均值的加权平均，权重与各自的精度（倒数方差）成正比。\n2.2 Beta-二项共轭（Beta-Binomial Conjugacy） 似然：$X | p \\sim \\text{Binomial}(n, p)$\n先验：$p \\sim \\text{Beta}(\\alpha, \\beta)$\n后验：$p | X \\sim \\text{Beta}(\\alpha + x, \\beta + n - x)$\n参数更新规则：\n若观测到 $x$ 次成功（共 $n$ 次试验）： $$\\alpha_{new} = \\alpha + x$$ $$\\beta_{new} = \\beta + (n - x)$$\n直观解释：\n$\\alpha$ 可理解为先验中\u0026quot;成功\u0026quot;的伪计数 $\\beta$ 可理解为先验中\u0026quot;失败\u0026quot;的伪计数 后验参数直接加上观测的成功和失败次数 特殊情况：\n无信息先验：$\\alpha = \\beta = 1$（均匀分布） Jeffreys 先验：$\\alpha = \\beta = 0.5$ 2.3 Gamma-Poisson 共轭（Gamma-Poisson Conjugacy） 似然：$X | \\lambda \\sim \\text{Poisson}(\\lambda)$\n先验：$\\lambda \\sim \\text{Gamma}(\\alpha, \\beta)$\n后验：$\\lambda | X \\sim \\text{Gamma}(\\alpha + x, \\beta + 1)$\n参数更新规则（单个观测）： $$\\alpha_{new} = \\alpha + x$$ $$\\beta_{new} = \\beta + 1$$\n对 $n$ 个独立观测 $x_1, \\ldots, x_n$： $$\\alpha_{new} = \\alpha + \\sum_{i=1}^n x_i$$ $$\\beta_{new} = \\beta + n$$\n直观解释：\n$\\alpha$ 为形状参数，可理解为先验观测的总事件数 $\\beta$ 为速率参数，可理解为先验观测的周期数 后验参数加上观测的事件总数和周期数 2.4 Gamma-指数共轭（Gamma-Exponential Conjugacy） 似然：$X | \\lambda \\sim \\text{Exp}(\\lambda)$，密度为 $f(x|\\lambda) = \\lambda e^{-\\lambda x}$\n先验：$\\lambda \\sim \\text{Gamma}(\\alpha, \\beta)$\n后验：$\\lambda | x_1, \\ldots, x_n \\sim \\text{Gamma}\\left(\\alpha + n, \\beta + \\sum_{i=1}^n x_i\\right)$\n参数更新规则： $$\\alpha_{new} = \\alpha + n$$ $$\\beta_{new} = \\beta + \\sum_{i=1}^n x_i$$\n2.5 Dirichlet-多项共轭（Dirichlet-Multinomial Conjugacy） 似然：$\\mathbf{X} | \\mathbf{p} \\sim \\text{Multinomial}(n, \\mathbf{p})$\n其中 $\\mathbf{p} = (p_1, \\ldots, p_k)$，$\\sum_{j=1}^k p_j = 1$\n先验：$\\mathbf{p} \\sim \\text{Dirichlet}(\\alpha_1, \\ldots, \\alpha_k)$\n后验：$\\mathbf{p} | \\mathbf{X} \\sim \\text{Dirichlet}(\\alpha_1 + n_1, \\ldots, \\alpha_k + n_k)$\n其中 $n_j$ 为第 $j$ 类的观测计数。\n参数更新规则： $$\\alpha_{j,new} = \\alpha_j + n_j, \\quad j = 1, \\ldots, k$$\n特殊情况：\n对称 Dirichlet 先验：$\\alpha_1 = \\cdots = \\alpha_k = \\alpha$ 无信息先验：$\\alpha = 1$（均匀 Dirichlet） 2.6 正态-正态共轭（方差未知） 似然：$X | \\mu, \\sigma^2 \\sim N(\\mu, \\sigma^2)$\n先验：\n$\\mu | \\sigma^2 \\sim N(\\mu_0, \\sigma^2/\\kappa_0)$ $\\sigma^2 \\sim \\text{Inv-Gamma}(\\nu_0/2, \\nu_0\\sigma_0^2/2)$ 后验：\n$\\mu | \\sigma^2, \\mathbf{x} \\sim N(\\mu_n, \\sigma^2/\\kappa_n)$ $\\sigma^2 | \\mathbf{x} \\sim \\text{Inv-Gamma}(\\nu_n/2, \\nu_n\\sigma_n^2/2)$ 参数更新规则（$n$ 个观测，$\\bar{x}$ 为样本均值，$s^2 = \\sum_{i=1}^n (x_i - \\bar{x})^2$）：\n$$\\kappa_n = \\kappa_0 + n$$\n$$\\mu_n = \\frac{\\kappa_0 \\mu_0 + n\\bar{x}}{\\kappa_0 + n}$$\n$$\\nu_n = \\nu_0 + n$$\n$$\\sigma_n^2 = \\frac{\\nu_0\\sigma_0^2 + (n-1)s^2 + \\frac{\\kappa_0 n}{kappa_0 + n}(\\bar{x} - \\mu_0)^2}{\\nu_0 + n}$$\n3. 共轭先验总结表 似然函数 共轭先验族 后验分布 先验参数 $\\text{Binomial}(n, p)$ Beta Beta $\\alpha, \\beta$ $\\text{Poisson}(\\lambda)$ Gamma Gamma $\\alpha, \\beta$ $\\text{Exp}(\\lambda)$ Gamma Gamma $\\alpha, \\beta$ $\\text{Geometric}(p)$ Beta Beta $\\alpha, \\beta$ $\\text{Uniform}(0, \\theta)$ Pareto Pareto $\\alpha, x_0$ $N(\\mu, \\sigma_0^2)$ Normal Normal $\\mu_0, \\tau_0^2$ $\\text{Multinomial}(n, \\mathbf{p})$ Dirichlet Dirichlet $\\boldsymbol{\\alpha}$ 4. 贝叶斯更新的递推性质 共轭先验的一个重要性质是**递推贝叶斯（sequential Bayes）**的便利性：\n$$\\text{后验}n = \\text{先验}{n+1}$$\n即，第 $n$ 次观测后的后验分布可作为第 $n+1$ 次观测的先验分布。\n例子（Beta-Binomial）：\n初始先验：$p \\sim \\text{Beta}(2, 2)$ 观测 1 次成功，1 次失败：后验 $\\sim \\text{Beta}(3, 3)$ 新观测 2 次成功，0 次失败：新后验 $\\sim \\text{Beta}(5, 3)$ 5. 超参数的先验解释 对于许多共轭先验，其参数具有明确的概率解释：\n5.1 Beta 分布 $\\alpha - 1$：先验中\u0026quot;成功\u0026quot;的伪计数 $\\beta - 1$：先验中\u0026quot;失败\u0026quot;的伪计数 $\\alpha + \\beta - 2$：先验总伪计数 5.2 Gamma 分布 $\\alpha$：形状参数，对应伪观测的总值 $\\beta$：速率参数，对应伪观测次数 先验中位数：$E[X] = \\alpha/\\beta$ 5.3 Dirichlet 分布 $\\alpha_j - 1$：第 $j$ 类的伪计数 $\\sum_j(\\alpha_j - 1)$：总伪计数 $\\text{Dir}(\\mathbf{1})$（所有 $\\alpha_j = 1$）为无信息先验 6. 共轭先验与无信息先验 虽然共轭先验主要是为了计算便利，但某些共轭先验可作为无信息（或弱信息）先验：\n分布 无信息/弱信息先验 说明 Beta $\\text{Beta}(1, 1)$ 均匀分布 Gamma $\\text{Gamma}(\\epsilon, \\epsilon)$，$\\epsilon \\to 0$ 非正规化 Jeffreys 先验 Normal $N(\\mu_0, \\tau_0^2)$，$\\tau_0 \\to \\infty$ 方差趋于无穷 Dirichlet $\\text{Dir}(\\mathbf{1})$ 对称无信息先验 7. 参考文献 Gelman, A., et al. (2013). Bayesian Data Analysis (3rd ed.). Chapman and Hall/CRC. Robert, C. P., \u0026amp; Casella, G. (2004). Monte Carlo Statistical Methods (2nd ed.). Springer. Bernardo, J. M., \u0026amp; Smith, A. F. (2009). Bayesian Theory. Wiley. Murphy, K. P. (2012). Machine Learning: A Probabilistic Perspective. MIT Press. ","permalink":"https://zbw.uk/posts/math/%E8%B4%9D%E5%8F%B6%E6%96%AF-%E5%85%B1%E8%BD%AD%E5%85%88%E9%AA%8C/","summary":"\u003cp\u003e共轭先验（conjugate prior）是贝叶斯统计中的一个重要概念，使得后验分布与先验分布具有相同的函数形式，大大简化了贝叶斯推断的计算。\u003c/p\u003e","title":"共轭先验"},{"content":"某些有特殊性质的概率分布族被称为位置参数族（location family）和尺度参数族（scale family），能够简化计算。\n1. 位置参数族 1.1 定义 设 $f(x)$ 是一个标准的概率密度函数。位置参数族定义为：\n$$f(x|\\mu) = f(x - \\mu)$$\n其中 $\\mu$ 称为位置参数（location parameter）。\n直观理解：位置参数 $\\mu$ 控制分布的中心位置，不改变分布的形状。\n1.2 性质 对于位置参数族分布 $X \\sim f(x|\\mu)$，若 $X_0 \\sim f(x)$（标准分布），则：\n$X = X_0 + \\mu$ $E[X] = E[X_0] + \\mu$ $\\text{Var}(X) = \\text{Var}(X_0)$ 密度函数平移：$f(x|\\mu) = f_0(x - \\mu)$ 1.3 常见例子 正态分布：$N(\\mu, \\sigma^2)$，其中 $\\sigma^2$ 已知\n标准形式：$N(0, \\sigma^2)$ 一般形式：$f(x|\\mu) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)$ 均匀分布：$U(\\mu, \\mu + 1)$\n标准形式：$U(0, 1)$ 平移后：$f(x|\\mu) = \\mathbf{1}_{[\\mu, \\mu+1]}(x)$ 指数分布族的某些形式\n2. 尺度参数族 2.1 定义 设 $f(x)$ 是一个标准的概率密度函数。尺度参数族定义为：\n$$f(x|\\sigma) = \\frac{1}{\\sigma} f\\left(\\frac{x}{\\sigma}\\right)$$\n其中 $\\sigma \u0026gt; 0$ 称为尺度参数（scale parameter）。\n直观理解：尺度参数 $\\sigma$ 控制分布的宽度或扩散程度，不改变分布的形状。\n2.2 性质 对于尺度参数族分布 $X \\sim f(x|\\sigma)$，若 $X_0 \\sim f(x)$（标准分布），则：\n$X = \\sigma X_0$ $E[X] = \\sigma E[X_0]$ $\\text{Var}(X) = \\sigma^2 \\text{Var}(X_0)$ 密度函数缩放：$f(x|\\sigma) = \\frac{1}{\\sigma} f_0(x/\\sigma)$ 2.3 常见例子 指数分布：$\\text{Exp}(\\lambda)$ 或 $\\text{Exp}(\\beta)$\n参数化形式：$f(x|\\beta) = \\frac{1}{\\beta} \\exp(-x/\\beta)$，$x \u0026gt; 0$ 其中 $\\beta$ 为尺度参数 正态分布：$N(0, \\sigma^2)$，其中 $\\mu = 0$\n$f(x|\\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right)$ Gamma 分布：$\\text{Gamma}(k, \\theta)$\n形状参数 $k$（无量纲） 尺度参数 $\\theta$ Pareto 分布等\n3. 位置-尺度参数族 3.1 定义 结合位置参数 $\\mu$ 和尺度参数 $\\sigma$，可定义位置-尺度参数族：\n$$f(x|\\mu, \\sigma) = \\frac{1}{\\sigma} f\\left(\\frac{x-\\mu}{\\sigma}\\right)$$\n其中 $\\mu \\in \\mathbb{R}$，$\\sigma \u0026gt; 0$。\n3.2 常见例子 正态分布：$N(\\mu, \\sigma^2)$ $$f(x|\\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)$$\n均匀分布：$U(\\mu, \\mu + \\sigma)$\nCauchy 分布：$\\text{Cauchy}(\\mu, \\sigma)$\nLaplace 分布：$f(x|\\mu, \\sigma) = \\frac{1}{2\\sigma}\\exp\\left(-\\frac{|x-\\mu|}{\\sigma}\\right)$\n4. 贝叶斯分析 4.1 位置参数的先验 对于位置参数 $\\mu$，常用的无信息先验包括：\nLebesgue 先验（广义均匀分布）：$\\pi(\\mu) \\propto 1$ 法瓦德先验（Jeffreys prior）：$\\pi(\\mu) \\propto 1$ 特点：\n对所有位置 $\\mu$ 给予相同的先验概率 具有位置不变性（location invariance） 4.2 尺度参数的先验 对于尺度参数 $\\sigma$，常用的无信息先验包括：\nJeffreys 先验：$\\pi(\\sigma) \\propto \\frac{1}{\\sigma}$ 对数-Uniform 先验：$\\pi(\\log \\sigma) \\propto 1$，等价于 $\\pi(\\sigma) \\propto \\frac{1}{\\sigma}$ 特点：\n对对数尺度是平坦的 具有尺度不变性（scale invariance） 4.3 后验推断 例子：正态分布 $N(\\mu, \\sigma_0^2)$，$\\sigma_0$ 已知\n先验：$\\pi(\\mu) \\propto 1$\n观测数据：$x_1, \\ldots, x_n$\n后验分布： $$\\mu | x_1, \\ldots, x_n \\sim N\\left(\\bar{x}, \\frac{\\sigma_0^2}{n}\\right)$$\n其中 $\\bar{x} = \\frac{1}{n}\\sum_{i=1}^n x_i$ 为样本均值。\n5. 数值应用 5.1 可信区间（Credible Interval） 对于位置参数，$(1-\\alpha) \\times 100%$ 的可信区间为： $$\\left[\\bar{x} - z_{\\alpha/2}\\frac{\\sigma_0}{\\sqrt{n}}, \\bar{x} + z_{\\alpha/2}\\frac{\\sigma_0}{\\sqrt{n}}\\right]$$\n对于尺度参数，通常需要使用数值方法或 MCMC 进行计算。\n5.2 预测分布 对于新观测 $\\tilde{x}$，其预测分布为： $$\\tilde{x} | x_1, \\ldots, x_n \\sim N\\left(\\bar{x}, \\sigma_0^2 + \\frac{\\sigma_0^2}{n}\\right)$$\n6. 总结 特性 位置参数 尺度参数 定义 $f(x|\\mu) = f(x-\\mu)$ $f(x|\\sigma) = \\frac{1}{\\sigma}f(x/\\sigma)$ 作用 控制分布中心 控制分布宽度 无信息先验 $\\pi(\\mu) \\propto 1$ $\\pi(\\sigma) \\propto 1/\\sigma$ 不变性 位置不变性 尺度不变性 常见分布 正态分布、均匀分布 指数分布、Gamma分布 参考文献 Gelman, A., et al. (2013). Bayesian Data Analysis (3rd ed.) Robert, C. P., \u0026amp; Casella, G. (2004). Monte Carlo Statistical Methods Kass, R. E., \u0026amp; Wasserman, L. (1996). The Selection of Prior Distributions by Formal Rules ","permalink":"https://zbw.uk/posts/math/%E8%B4%9D%E5%8F%B6%E6%96%AF-%E5%B0%BA%E5%BA%A6%E4%B8%8E%E4%BD%8D%E7%BD%AE%E5%8F%82%E6%95%B0%E6%97%8F/","summary":"\u003cp\u003e某些有特殊性质的概率分布族被称为位置参数族（location family）和尺度参数族（scale family），能够简化计算。\u003c/p\u003e","title":"尺度与位置参数"},{"content":"考虑到很多常见问题的目标函数都是仿射或二次型形式的，若其为凸函数，梯度为0的点即为最优解。因此，在最小二乘等问题中常要对矩阵求导。\n基本规则 设 $A \\in \\mathbb{R}^{m \\times n}$，$x \\in \\mathbb{R}^{n}$，$b \\in \\mathbb{R}^{m}$，对如下 $\\mathbb{R}^n \\to \\mathbb{R}$ 的函数求导：\n常数函数: 当然为0 线性函数: $f(x) = a^T x$，则 $\\nabla f(x) = a$ 二次型: $f(x) = x^T A x$，则 $\\nabla f(x) = (A + A^T) x$。若 $A$ 对称，则 $\\nabla f(x) = 2 A x$ 最小二乘 考虑如下最小二乘问题： $$ \\min_x | A x - b |_2^2 $$ 即： $$ \\min_x (A x - b)^T (A x - b) $$ 展开： $$ \\min_x x^T A^T A x - 2 b^T A x + b^T b $$ 对 $x$ 求导，应用以上三种规则： $$ \\nabla_x = 2 A^T A x - 2 A^T b $$ 令梯度为0，解得： $$ x = (A^T A)^{-1} A^T b $$\n","permalink":"https://zbw.uk/posts/math/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC/","summary":"\u003cp\u003e考虑到很多常见问题的目标函数都是仿射或二次型形式的，若其为凸函数，梯度为0的点即为最优解。因此，在最小二乘等问题中常要对矩阵求导。\u003c/p\u003e","title":"对矩阵求导"},{"content":"债券基础 债券(bond)包含如下要素：票面金额(face value)、票面利率(coupon rate)、到期时间(maturity date)和发行价格(issue price)等，其义自见。在市场发行或交易时，其收益率(yield)还受价格影响。\n当发行人(issuer)为某国政府时，称为国债(government bond)或主权债券(sovereign bond)。由于政府违约风险较低，（短期）国债通常被视为无风险利率。\n国债收益率曲线 不同期限的债券通常收益率也不同。事实上，假设预期\n","permalink":"https://zbw.uk/posts/finance/bond/","summary":"\u003ch2 id=\"债券基础\"\u003e债券基础\u003c/h2\u003e\n\u003cp\u003e债券(bond)包含如下要素：票面金额(face value)、票面利率(coupon rate)、到期时间(maturity date)和发行价格(issue price)等，其义自见。在市场发行或交易时，其收益率(yield)还受价格影响。\u003c/p\u003e","title":"债券、国债与国债收益率曲线"},{"content":"KL 散度（KL Divergence），是衡量两个概率分布之间差异的一种非对称度量。对分布 $P(x)$ 和 $Q(x)$，KL 散度可以被理解为按照 $P(x)$ 或 $Q(x)$ 加权的对数似然比的期望值： $$ D_{KL}(P || Q) = \\mathbb{E}{x \\sim P} \\left[ \\log \\frac{P(x)}{Q(x)} \\right] $$ 对于离散分布，KL 散度定义为： $$ \\sum{x} P(x) \\log \\frac{P(x)}{Q(x)} $$ 对于连续分布，KL 散度定义为： $$ \\int P(x) \\log \\frac{P(x)}{Q(x)} dx $$\n性质 非负性 从Jenson不等式可以导出KL散度的非负性： $$ D_{KL}(P || Q) = \\mathbb{E}{x \\sim P} \\left[ -\\log \\frac{Q(x)}{P(x)} \\right] \\geq -\\log \\mathbb{E}{x \\sim P} \\left[ \\frac{Q(x)}{P(x)} \\right] = -\\log 1 = 0 $$\n也可直接用基本不等式： $$ D_{KL}(P || Q) = \\sum_{x} P(x) \\log \\frac{P(x)}{Q(x)} \\geq \\sum_{x} P(x) (1 - \\frac{Q(x)}{P(x)}) = \\sum_{x} P(x) - \\sum_x Q(x) = 0 $$\n非对称性 这是显然的，$D_{KL}(P || Q)$，可以理解为$P$ 是真实分布，故用 $P$ 加权。\nKL 散度与交叉熵 交叉熵定义为： $$ H(P, Q) = - \\mathbb{E}_{x \\sim P} [\\log Q(x)] $$\n因此，KL 散度可以表示为交叉熵与熵的差值： $$ D_{KL}(P || Q) = H(P, Q) - H(P) $$\n其中，$H(P)$ 是分布 $P$ 的熵，定义为： $$ H(P) = - \\mathbb{E}_{x \\sim P} [\\log P(x)] $$\n由于在给定一组数据的情况下，$H(P)$ 是常数，因此最小化 KL 散度等价于最小化交叉熵。\n分类问题中的交叉熵 在分类问题中，真实标签通常使用独热编码（one-hot encoding）表示。对某样本，其为 One-hot 编码 $\\mathbf{y}$，预测概率分布为 $\\hat{\\mathbf{y}}$，则交叉熵损失函数为： $$ L = - \\sum_{i} y_i \\log \\hat{y}_i $$ 但由于 $\\mathbf{y}$ 是独热编码，只有一个元素为1，其余为0，因此损失函数简化为： $$ L = - \\log \\hat{y}_k $$ 其中，$k$ 是真实类别的索引。\n","permalink":"https://zbw.uk/posts/math/kl/","summary":"\u003cp\u003eKL 散度（KL Divergence），是衡量两个概率分布之间差异的一种非对称度量。对分布 $P(x)$ 和 $Q(x)$，KL 散度可以被理解为按照 $P(x)$ 或 $Q(x)$ 加权的对数似然比的期望值：\n$$ D_{KL}(P || Q) = \\mathbb{E}\u003cem\u003e{x \\sim P} \\left[ \\log \\frac{P(x)}{Q(x)} \\right] $$\n对于离散分布，KL 散度定义为：\n$$ \\sum\u003c/em\u003e{x} P(x) \\log \\frac{P(x)}{Q(x)} $$\n对于连续分布，KL 散度定义为：\n$$ \\int P(x) \\log \\frac{P(x)}{Q(x)} dx $$\u003c/p\u003e","title":"KL散度与MLE、MAP"},{"content":"Jenson 不等式 对于凸函数 $f$，有如下不等式成立： $$ E[f(X)] \\geq f(E[X]) $$\n算术-几何均值不等式是 Jenson 不等式取 $X$ 服从两点分布的特例。取 $f(x) = x^2$, 得方差的非负性。\nYoung 不等式 设 $a, b \\geq 0$，$p, q \u0026gt; 1$ 且 $\\frac{1}{p} + \\frac{1}{q} = 1$，则有 $$ ab \\leq \\frac{a^p}{p} + \\frac{b^q}{q} $$\n证明可由 Jenson 不等式导出。取 $f(x) = e^x$，$X$ 服从两点分布，取 $ln(a^{p})$ 和 $ln(b^{q})$ 两点的概率分别为 $\\frac{1}{p}$ 和 $\\frac{1}{q}$。\nHölder 不等式 设 $X, Y$ 为随机变量，则有 $$ E[|XY|] \\leq (E[|X|^p])^{1/p} (E[|Y|^q])^{1/q} $$ 设 $p, q \u0026gt; 1$ 且 $\\frac{1}{p} + \\frac{1}{q} = 1$，则对于任意实数列 $(a_i), (b_i)$ 有 $$ \\sum_{i} |a_i b_i| \\leq \\left( \\sum_{i} |a_i|^p \\right)^{1/p} \\left( \\sum_{i} |b_i|^q \\right)^{1/q} $$\n证明可由 Young 不等式导出。对每一项应用 Young 不等式，然后对所有项求和。\n首先，设 $u_i = \\frac{|a_i|}{(\\sum_{j} |a_j|^p)^{1/p}}$，$v_i = \\frac{|b_i|}{(\\sum_{j} |b_j|^q)^{1/q}}$，则有 $$ |a_i b_i| = (\\sum_{j} |a_j|^p)^{1/p} (\\sum_{j} |b_j|^q)^{1/q} |u_i v_i| $$\n只需证明 $\\sum_{i} |u_i v_i| \\leq 1$。应用 Young 不等式，有 $$ |u_i v_i| \\leq \\frac{|u_i|^p}{p} + \\frac{|v_i|^q}{q} $$ 由于 $\\sum_{i} |u_i|^p = 1$ 和 $\\sum_{i} |v_i|^q = 1$，所以 $$ \\sum_{i} |u_i v_i| \\leq \\frac{1}{p} + \\frac{1}{q} = 1 $$\nHölder 用于控制两个随机变量乘积的期望，其不大于各自某个 $L_p$ 范数的乘积。在机器学习中，Hölder 不等式常用于分析模型的泛化误差、正则化项以及优化算法的收敛性。\nCauthy-Schwarz 不等式 Cauthy-Schwarz 不等式是 Hölder 不等式取 $p = q = 2$ 后，两侧平方的特例。\n设 $X, Y$ 为随机变量，则有 $$ (E[XY])^2 \\leq E[X^2] E[Y^2] $$\n设 $(a_i), (b_i)$ 为任意实数列，则有 $$ \\left( \\sum_{i} a_i b_i \\right)^2 \\leq \\left( \\sum_{i} a_i^2 \\right) \\left( \\sum_{i} b_i^2 \\right) $$\n或连续形式： $$ \\left( \\int_a^b f(x) g(x) dx \\right)^2 \\leq \\left( \\int_a^b f(x)^2 dx \\right) \\left( \\int_a^b g(x)^2 dx \\right) $$ 其中， $f(x), g(x)$ 为区间 $[a, b]$ 上的可积函数。\nMinkowski 不等式 设 $X, Y$ 为随机变量，则有 $$ (E[|X + Y|^p])^{1/p} \\leq (E[|X|^p])^{1/p} + (E[|Y|^p])^{1/p} $$ 设 $p \\geq 1$，则对于任意实数列 $(a_i), (b_i)$ 有 $$ \\left( \\sum_{i} |a_i + b_i|^p \\right)^{1/p} \\leq \\left( \\sum_{i} |a_i|^p \\right)^{1/p} + \\left( \\sum_{i} |b_i|^p \\right)^{1/p} $$\n证明可由 Hölder 不等式导出。设 $S = \\left( \\sum_{i} |a_i + b_i|^p \\right)^{1/p}$，则有 $$ S^p = \\sum_{i} |a_i + b_i|^p = \\sum_{i} |a_i + b_i|^{p-1} |a_i| + \\sum_{i} |a_i + b_i|^{p-1} |b_i| $$ 应用 Hölder 不等式，有 $$ \\sum_{i} |a_i + b_i|^{p-1} |a_i| \\leq \\left( \\sum_{i} |a_i + b_i|^p \\right)^{(p-1)/p} \\left( \\sum_{i} |a_i|^p \\right)^{1/p} = S^{p-1} \\left( \\sum_{i} |a_i|^p \\right)^{1/p} $$ 类似地， $$ \\sum_{i} |a_i + b_i|^{p-1} |b_i| \\leq S^{p-1} \\left( \\sum_{i} |b_i|^p \\right)^{1/p} $$ 将两式相加，得到 $$ S^p \\leq S^{p-1} \\left( \\sum_{i} |a_i|^p \\right)^{1/p} + S^{p-1} \\left( \\sum_{i} |b_i|^p \\right)^{1/p} $$ 两边除以 $S^{p-1}$（$S \u0026gt; 0$），得到 Minkowski 不等式。\nMinkowski 不等式是 $L_p$ 空间中范数的三角不等式。\n","permalink":"https://zbw.uk/posts/math/inequity/","summary":"\u003ch2 id=\"jenson-不等式\"\u003eJenson 不等式\u003c/h2\u003e\n\u003cp\u003e对于凸函数 $f$，有如下不等式成立：\n$$ E[f(X)] \\geq f(E[X]) $$\u003c/p\u003e","title":"概率论中的常见不等式"}]